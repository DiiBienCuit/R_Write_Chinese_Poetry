temp_file <- temp_file[nchar(temp_file) == nchar(cipai_2[i])]
empty <- paste0(empty, sample(temp_file,1))
}
result <- paste0(substr(empty, 1,4), ",", substr(empty,5,9),"。",
substr(empty, 10,16), ",", substr(empty, 17,22),"。",
substr(empty, 23,28), ",", substr(empty, 29,34),"。",
substr(empty, 35,40), ",", substr(empty, 41,46),"。")
}
lapply(1, write_songci)
lapply(3, write_songci)
lapply(1:3, write_songci)
lapply(1:3, write_songci)
lapply(1:3, write_songci)
sapply(1:5, write_songci)
index = c(1:5)
lapply(index, write_songci)
sapply(1:5,write_songci)
write_songci
write_songci(2)
library(jiebaR)
library(wordcloud2)
fileName <- "宋詞三百首.txt"
SC <- readChar(fileName, file.info(fileName)$size)
#读取中文不出现乱码
Encoding(SC) <-  "UTF-8"
substr(SC, 1000, 1100)
#分词
mixseg = worker()
analysis <- as.data.frame(table(mixseg[SC]))
#clean alphabet values
indice <- c(1:13)
analysis_2 <- analysis[-indice,]
# 重新排序
analysis_2 <- analysis_2[order(-analysis_2$freq),]
# 简单改变一下文件的命名、格式
names(analysis) <- c("word","freq")
analysis$word <- as.character(analysis$word)
# 看一下这个分词文件的开头
#wordcloud2(analysis_2)
#wordcloud2(analysis[analysis$freq>1& analysis$freq < 300 & nchar(analysis$word) == 1,])
#wordcloud2(analysis[analysis$freq>1& analysis$freq < 300 & nchar(analysis$word) == 2,])
#wordcloud2(analysis[analysis$freq>1 & analysis$freq < 300 & nchar(analysis$word) == 3,])
cipai <- "自春來、慘綠愁紅，芳心是事可可。日上花稍，鶯穿柳帶，猶壓香衾臥。暖酥消，膩雲嚲。終日厭厭倦梳裹。無那。恨薄情一去，音書無箇。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
example <- subset(analysis_2, freq >1 & nchar(word) <3 & freq < 300)
# 提取词性文件
cixing <- attributes(cipai_2)$names
# 将素材库进行词性分类
example_2 <- tagger <= example$word
write_songci <- function(m){
set.seed(m)
empty <- ""
for (i in 1:length(cipai_2)){
#get the first chr who has the same type as the original one
temp_file <- example_2[attributes(example_2)$name == cixing[i]]
#who gets the same nomber of chrs as the original one
temp_file <- temp_file[nchar(temp_file) == nchar(cipai_2[i])]
empty <- paste0(empty, sample(temp_file,1))
}
result <- paste0(substr(empty, 1,4), ",", substr(empty,5,9),"。",
substr(empty, 10,16), ",", substr(empty, 17,22),"。",
substr(empty, 23,28), ",", substr(empty, 29,34),"。",
substr(empty, 35,40), ",", substr(empty, 41,46),"。")
}
write_songci(2)
index = c(1:5)
lapply(index, write_songci)
cipai <- "自春來慘綠愁紅，芳心是事可可。日上花稍，鶯穿柳帶，猶壓香衾臥。暖酥消，膩雲嚲。終日厭厭倦梳裹。無那。恨薄情一去，音書無箇。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
cipai <- "沙上並禽池上暝。雲破月來花弄影。重重簾幕密遮燈，風不定。人初靜。明日落紅應滿徑。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
library(jiebaR)
library(wordcloud2)
fileName <- "宋詞三百首.txt"
SC <- readChar(fileName, file.info(fileName)$size)
#读取中文不出现乱码
Encoding(SC) <-  "UTF-8"
substr(SC, 1000, 1100)
#分词
mixseg = worker()
analysis <- as.data.frame(table(mixseg[SC]))
#clean alphabet values
indice <- c(1:13)
analysis_2 <- analysis[-indice,]
# 重新排序
analysis_2 <- analysis_2[order(-analysis_2$freq),]
# 简单改变一下文件的命名、格式
names(analysis) <- c("word","freq")
analysis$word <- as.character(analysis$word)
# 看一下这个分词文件的开头
#wordcloud2(analysis_2)
#wordcloud2(analysis[analysis$freq>1& analysis$freq < 300 & nchar(analysis$word) == 1,])
#wordcloud2(analysis[analysis$freq>1& analysis$freq < 300 & nchar(analysis$word) == 2,])
#wordcloud2(analysis[analysis$freq>1 & analysis$freq < 300 & nchar(analysis$word) == 3,])
cipai <- "沙上並禽池上暝。雲破月來花弄影。重重簾幕密遮燈，風不定。人初靜。明日落紅應滿徑。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
example <- subset(analysis_2, freq >1 & nchar(word) <3 & freq < 300)
# 提取词性文件
cixing <- attributes(cipai_2)$names
# 将素材库进行词性分类
example_2 <- tagger <= example$word
write_songci <- function(m){
set.seed(m)
empty <- ""
for (i in 1:length(cipai_2)){
#get the first chr who has the same type as the original one
temp_file <- example_2[attributes(example_2)$name == cixing[i]]
#who gets the same nomber of chrs as the original one
temp_file <- temp_file[nchar(temp_file) == nchar(cipai_2[i])]
empty <- paste0(empty, sample(temp_file,1))
}
result <- paste0(substr(empty, 1,4), ",", substr(empty,5,9),"。",
substr(empty, 10,16), ",", substr(empty, 17,22),"。",
substr(empty, 23,28), ",", substr(empty, 29,34),"。",
substr(empty, 35,40), ",", substr(empty, 41,46),"。")
}
write_songci(2)
index = c(1:5)
lapply(index, write_songci)
library(jiebaR)
library(wordcloud2)
fileName <- "宋詞三百首.txt"
SC <- readChar(fileName, file.info(fileName)$size)
#读取中文不出现乱码
Encoding(SC) <-  "UTF-8"
substr(SC, 1000, 1100)
#分词
mixseg = worker()
analysis <- as.data.frame(table(mixseg[SC]))
#clean alphabet values
indice <- c(1:13)
analysis_2 <- analysis[-indice,]
# 重新排序
analysis_2 <- analysis_2[order(-analysis_2$freq),]
# 简单改变一下文件的命名、格式
names(analysis) <- c("word","freq")
analysis$word <- as.character(analysis$word)
# 看一下这个分词文件的开头
#wordcloud2(analysis_2)
#wordcloud2(analysis[analysis$freq>1& analysis$freq < 300 & nchar(analysis$word) == 1,])
#wordcloud2(analysis[analysis$freq>1& analysis$freq < 300 & nchar(analysis$word) == 2,])
#wordcloud2(analysis[analysis$freq>1 & analysis$freq < 300 & nchar(analysis$word) == 3,])
cipai <- "画堂晨起，来报雪花坠。高卷帘栊 看 佳瑞，皓色远 迷 庭砌。盛气光引 炉烟，素草寒生玉佩。应是天仙狂醉，乱把白云揉碎。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
example <- subset(analysis_2, freq >1 & nchar(word) <3 & freq < 300)
# 提取词性文件
cixing <- attributes(cipai_2)$names
# 将素材库进行词性分类
example_2 <- tagger <= example$word
write_songci <- function(m){
set.seed(m)
empty <- ""
for (i in 1:length(cipai_2)){
#get the first chr who has the same type as the original one
temp_file <- example_2[attributes(example_2)$name == cixing[i]]
#who gets the same nomber of chrs as the original one
temp_file <- temp_file[nchar(temp_file) == nchar(cipai_2[i])]
empty <- paste0(empty, sample(temp_file,1))
}
result <- paste0(substr(empty, 1,4), ",", substr(empty,5,9),"。",
substr(empty, 10,16), ",", substr(empty, 17,22),"。",
substr(empty, 23,28), ",", substr(empty, 29,34),"。",
substr(empty, 35,40), ",", substr(empty, 41,46),"。")
}
write_songci(2)
index = c(1:5)
lapply(index, write_songci)
cipai <- "李清照,画堂晨起，来报雪花坠。高卷帘栊 看 佳瑞，皓色远 迷 庭砌。盛气光引 炉烟，素草寒生玉佩。应是天仙狂醉，乱把白云揉碎。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
cipai <- "画堂晨起，来报雪花坠。高卷帘栊 看 佳瑞，皓色远 迷 庭砌。盛气光引 炉烟，素草寒生玉佩。应是天仙狂醉，乱把白云揉碎。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
lapply(index, write_songci)
index = c(1:10)
lapply(index, write_songci)
library(jiebaR)
library(wordcloud2)
fileName <- "唐詩三百首.txt"
SC <- readChar(fileName, file.info(fileName)$size)
#读取中文不出现乱码
Encoding(SC) <-  "UTF-8"
substr(SC, 1000, 1100)
#分词
mixseg = worker()
analysis_2 <- as.data.frame(table(mixseg[SC]))
#clean alphabet values
# 重新排序
analysis_2 <- analysis_2[order(-analysis_2$freq),]
# 简单改变一下文件的命名、格式
names(analysis) <- c("word","freq")
analysis$word <- as.character(analysis$word)
wordcloud2(analysis_2)
View(analysis_2)
analysis_2 <- analysis_2[order(-analysis_2$freq),]
names(analysis) <- c("word","freq")
analysis$word <- as.character(analysis$word)
names(analysis_2) <- c("word","freq")
analysis_2$word <- as.character(analysis_2$word)
# 重新排序
analysis_2 <- analysis_2[order(-analysis_2$freq),]
wordcloud2(analysis[analysis$freq>1& analysis$freq < 50 & nchar(analysis$word) == 1,])
wordcloud2(analysis[analysis$freq>1& analysis$freq < 50 & nchar(analysis$word) == 2,])
wordcloud2(analysis[analysis$freq>1 & analysis$freq < 50 & nchar(analysis$word) == 3,])
wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 50 & nchar(analysis_2$word) == 1,])
wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 50 & nchar(analysis_2$word) == 2,])
wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 15 & nchar(analysis_2$word) == 2,])
wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 13 & nchar(analysis_2$word) == 2,])
wordcloud2(analysis_2[analysis_2$freq>1 & analysis_2$freq < 50 & nchar(analysis_2$word) == 3,])
wordcloud2(analysis_2[analysis_2$freq>1 & analysis_2$freq < 7 & nchar(analysis_2$word) == 3,])
wordcloud2(analysis_2[analysis_2$freq>1 & analysis_2$freq < 5 & nchar(analysis_2$word) == 3,])
wordcloud2(analysis_2[analysis_2$freq>1 & analysis_2$freq < 4 & nchar(analysis_2$word) == 3,])
library(jiebaR)
library(wordcloud2)
fileName <- "唐詩三百首.txt"
SC <- readChar(fileName, file.info(fileName)$size)
#读取中文不出现乱码
Encoding(SC) <-  "UTF-8"
substr(SC, 1000, 1100)
#分词
mixseg = worker()
analysis_2 <- as.data.frame(table(mixseg[SC]))
#clean alphabet values
# 简单改变一下文件的命名、格式
names(analysis_2) <- c("word","freq")
analysis_2$word <- as.character(analysis_2$word)
# 重新排序
analysis_2 <- analysis_2[order(-analysis_2$freq),]
# 看一下这个分词文件的开头
wordcloud2(analysis_2)
wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 50 & nchar(analysis_2$word) == 1,])
wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 13 & nchar(analysis_2$word) == 2,])
wordcloud2(analysis_2[analysis_2$freq>1 & analysis_2$freq < 4 & nchar(analysis_2$word) == 3,])
cipai <- "床前明月光，疑是地上霜。舉頭望明月，低頭思故鄉。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
example <- subset(analysis_2, freq >1 & nchar(word) <4 & freq < 50)
# 提取词性文件
cixing <- attributes(cipai_2)$names
# 将素材库进行词性分类
example_2 <- tagger <= example$word
write_songci <- function(m){
set.seed(m)
empty <- ""
for (i in 1:length(cipai_2)){
#get the first chr who has the same type as the original one
temp_file <- example_2[attributes(example_2)$name == cixing[i]]
#who gets the same nomber of chrs as the original one
temp_file <- temp_file[nchar(temp_file) == nchar(cipai_2[i])]
empty <- paste0(empty, sample(temp_file,1))
}
result <- paste0(substr(empty, 1,4), ",", substr(empty,5,9),"。",
substr(empty, 10,16), ",", substr(empty, 17,22),"。",
substr(empty, 23,28), ",", substr(empty, 29,34),"。",
substr(empty, 35,40), ",", substr(empty, 41,46),"。")
}
index = c(1:10)
lapply(index, write_songci)
library(jiebaR)
library(wordcloud2)
fileName <- "唐詩三百首.txt"
SC <- readChar(fileName, file.info(fileName)$size)
#读取中文不出现乱码
Encoding(SC) <-  "UTF-8"
substr(SC, 1000, 1100)
#分词
mixseg = worker()
analysis_2 <- as.data.frame(table(mixseg[SC]))
#clean alphabet values
# 简单改变一下文件的命名、格式
names(analysis_2) <- c("word","freq")
analysis_2$word <- as.character(analysis_2$word)
# 重新排序
analysis_2 <- analysis_2[order(-analysis_2$freq),]
# 看一下这个分词文件的开头
#wordcloud2(analysis_2)
#wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 50 & nchar(analysis_2$word) == 1,])
#wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 13 & nchar(analysis_2$word) == 2,])
#wordcloud2(analysis_2[analysis_2$freq>1 & analysis_2$freq < 4 & nchar(analysis_2$word) == 3,])
cipai <- "床前明月光，疑是地上霜。舉頭望明月，低頭思故鄉。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
example <- subset(analysis_2, freq >1 & nchar(word) <4 & freq < 50)
# 提取词性文件
cixing <- attributes(cipai_2)$names
# 将素材库进行词性分类
example_2 <- tagger <= example$word
write_songci <- function(m){
set.seed(m)
empty <- ""
for (i in 1:length(cipai_2)){
#get the first chr who has the same type as the original one
temp_file <- example_2[attributes(example_2)$name == cixing[i]]
#who gets the same nomber of chrs as the original one
temp_file <- temp_file[nchar(temp_file) == nchar(cipai_2[i])]
empty <- paste0(empty, sample(temp_file,1))
}
result <- paste0(substr(empty, 1,5), ",", substr(empty,6,10),"。",
substr(empty, 11,15), ",", substr(empty, 16,20),"。")
}
index = c(1:10)
lapply(index, write_songci)
cipai <- "歸山深淺去，須盡邱壑美。莫學武陵人，暫游桃源裡。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
library(jiebaR)
library(wordcloud2)
fileName <- "唐詩三百首.txt"
SC <- readChar(fileName, file.info(fileName)$size)
#读取中文不出现乱码
Encoding(SC) <-  "UTF-8"
substr(SC, 1000, 1100)
#分词
mixseg = worker()
analysis_2 <- as.data.frame(table(mixseg[SC]))
#clean alphabet values
# 简单改变一下文件的命名、格式
names(analysis_2) <- c("word","freq")
analysis_2$word <- as.character(analysis_2$word)
# 重新排序
analysis_2 <- analysis_2[order(-analysis_2$freq),]
# 看一下这个分词文件的开头
#wordcloud2(analysis_2)
#wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 50 & nchar(analysis_2$word) == 1,])
#wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 13 & nchar(analysis_2$word) == 2,])
#wordcloud2(analysis_2[analysis_2$freq>1 & analysis_2$freq < 4 & nchar(analysis_2$word) == 3,])
cipai <- "歸山深淺去，須盡邱壑美。莫學武陵人，暫游桃源裡。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
example <- subset(analysis_2, freq >1 & nchar(word) <4 & freq < 50)
# 提取词性文件
cixing <- attributes(cipai_2)$names
# 将素材库进行词性分类
example_2 <- tagger <= example$word
write_songci <- function(m){
set.seed(m)
empty <- ""
for (i in 1:length(cipai_2)){
#get the first chr who has the same type as the original one
temp_file <- example_2[attributes(example_2)$name == cixing[i]]
#who gets the same nomber of chrs as the original one
temp_file <- temp_file[nchar(temp_file) == nchar(cipai_2[i])]
empty <- paste0(empty, sample(temp_file,1))
}
result <- paste0(substr(empty, 1,5), ",", substr(empty,6,10),"。",
substr(empty, 11,15), ",", substr(empty, 16,20),"。")
}
index = c(1:10)
lapply(index, write_songci)
cipai <- "蜀僧抱綠綺，西下峨眉峰。為我一揮手，如聽萬壑松。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
cipai <- "前年戍月支，城下沒全師。蕃漢斷消息，死生長別離。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
library(jiebaR)
library(wordcloud2)
fileName <- "唐詩三百首.txt"
SC <- readChar(fileName, file.info(fileName)$size)
#读取中文不出现乱码
Encoding(SC) <-  "UTF-8"
substr(SC, 1000, 1100)
#分词
mixseg = worker()
analysis_2 <- as.data.frame(table(mixseg[SC]))
#clean alphabet values
# 简单改变一下文件的命名、格式
names(analysis_2) <- c("word","freq")
analysis_2$word <- as.character(analysis_2$word)
# 重新排序
analysis_2 <- analysis_2[order(-analysis_2$freq),]
# 看一下这个分词文件的开头
#wordcloud2(analysis_2)
#wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 50 & nchar(analysis_2$word) == 1,])
#wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 13 & nchar(analysis_2$word) == 2,])
#wordcloud2(analysis_2[analysis_2$freq>1 & analysis_2$freq < 4 & nchar(analysis_2$word) == 3,])
cipai <- "前年戍月支，城下沒全師。蕃漢斷消息，死生長別離。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
example <- subset(analysis_2, freq >1 & nchar(word) <4 & freq < 50)
# 提取词性文件
cixing <- attributes(cipai_2)$names
# 将素材库进行词性分类
example_2 <- tagger <= example$word
write_songci <- function(m){
set.seed(m)
empty <- ""
for (i in 1:length(cipai_2)){
#get the first chr who has the same type as the original one
temp_file <- example_2[attributes(example_2)$name == cixing[i]]
#who gets the same nomber of chrs as the original one
temp_file <- temp_file[nchar(temp_file) == nchar(cipai_2[i])]
empty <- paste0(empty, sample(temp_file,1))
}
result <- paste0(substr(empty, 1,5), ",", substr(empty,6,10),"。",
substr(empty, 11,15), ",", substr(empty, 16,20),"。")
}
index = c(1:10)
lapply(index, write_songci)
cipai <- "昨夜裙帶解，今朝蟢子飛。鉛華不可棄，莫是藁砧歸。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
library(jiebaR)
library(wordcloud2)
fileName <- "唐詩三百首.txt"
SC <- readChar(fileName, file.info(fileName)$size)
#读取中文不出现乱码
Encoding(SC) <-  "UTF-8"
substr(SC, 1000, 1100)
#分词
mixseg = worker()
analysis_2 <- as.data.frame(table(mixseg[SC]))
#clean alphabet values
# 简单改变一下文件的命名、格式
names(analysis_2) <- c("word","freq")
analysis_2$word <- as.character(analysis_2$word)
# 重新排序
analysis_2 <- analysis_2[order(-analysis_2$freq),]
# 看一下这个分词文件的开头
#wordcloud2(analysis_2)
#wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 50 & nchar(analysis_2$word) == 1,])
#wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 13 & nchar(analysis_2$word) == 2,])
#wordcloud2(analysis_2[analysis_2$freq>1 & analysis_2$freq < 4 & nchar(analysis_2$word) == 3,])
cipai <- "昨夜裙帶解，今朝蟢子飛。鉛華不可棄，莫是藁砧歸。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
example <- subset(analysis_2, freq >1 & nchar(word) <4 & freq < 50)
# 提取词性文件
cixing <- attributes(cipai_2)$names
# 将素材库进行词性分类
example_2 <- tagger <= example$word
write_songci <- function(m){
set.seed(m)
empty <- ""
for (i in 1:length(cipai_2)){
#get the first chr who has the same type as the original one
temp_file <- example_2[attributes(example_2)$name == cixing[i]]
#who gets the same nomber of chrs as the original one
temp_file <- temp_file[nchar(temp_file) == nchar(cipai_2[i])]
empty <- paste0(empty, sample(temp_file,1))
}
result <- paste0(substr(empty, 1,5), ",", substr(empty,6,10),"。",
substr(empty, 11,15), ",", substr(empty, 16,20),"。")
}
index = c(1:10)
lapply(index, write_songci)
library(jiebaR)
library(wordcloud2)
fileName <- "唐詩三百首.txt"
SC <- readChar(fileName, file.info(fileName)$size)
#读取中文不出现乱码
Encoding(SC) <-  "UTF-8"
substr(SC, 1000, 1100)
#分词
mixseg = worker()
analysis_2 <- as.data.frame(table(mixseg[SC]))
#clean alphabet values
# 简单改变一下文件的命名、格式
names(analysis_2) <- c("word","freq")
analysis_2$word <- as.character(analysis_2$word)
# 重新排序
analysis_2 <- analysis_2[order(-analysis_2$freq),]
# 看一下这个分词文件的开头
#wordcloud2(analysis_2)
#wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 50 & nchar(analysis_2$word) == 1,])
#wordcloud2(analysis_2[analysis_2$freq>1& analysis_2$freq < 13 & nchar(analysis_2$word) == 2,])
#wordcloud2(analysis_2[analysis_2$freq>1 & analysis_2$freq < 4 & nchar(analysis_2$word) == 3,])
cipai <- "昨夜裙帶解，今朝蟢子飛。鉛華不可棄，莫是藁砧歸。"
tagger <- worker("tag")
cipai_2 <- tagger <= cipai
cipai_2
example <- subset(analysis_2, freq >1 & nchar(word) <4 & freq < 50)
# 提取词性文件
cixing <- attributes(cipai_2)$names
# 将素材库进行词性分类
example_2 <- tagger <= example$word
write_tangshi <- function(m){
set.seed(m)
empty <- ""
for (i in 1:length(cipai_2)){
#get the first chr who has the same type as the original one
temp_file <- example_2[attributes(example_2)$name == cixing[i]]
#who gets the same nomber of chrs as the original one
temp_file <- temp_file[nchar(temp_file) == nchar(cipai_2[i])]
empty <- paste0(empty, sample(temp_file,1))
}
result <- paste0(substr(empty, 1,5), ",", substr(empty,6,10),"。",
substr(empty, 11,15), ",", substr(empty, 16,20),"。")
}
index = c(1:10)
lapply(index, write_tangshi)
